{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "train_bio_or_bieso.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqO9D4uwr_KP",
        "outputId": "07fc139a-f4a3-401d-b697-777c2f2fead6"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import os \n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/CCF/DBC_code/src\")\n",
        "!pip install bert4keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting bert4keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/d4/7125cf92a8a8274d3713e43c4979e188e5d741df7210fe88fc609ca11f7f/bert4keras-0.9.6.tar.gz (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras<=2.3.1 in /tensorflow-1.15.2/python3.6 (from bert4keras) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.6 (from keras<=2.3.1->bert4keras) (1.0.8)\n",
            "Building wheels for collected packages: bert4keras\n",
            "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert4keras: filename=bert4keras-0.9.6-cp36-none-any.whl size=42954 sha256=5ddc055c59d99d85d660ba7a5e2c4fbcbe83376313c0132e0e4cfb0080568ad3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/95/21/39b1a2052a034a39c63faf81821977d8b64df47961bbf95d52\n",
            "Successfully built bert4keras\n",
            "Installing collected packages: bert4keras\n",
            "Successfully installed bert4keras-0.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNz_LNO3q9pq",
        "outputId": "196d7bc8-8c94-46fc-96ed-4f6892aa8baa"
      },
      "source": [
        "import tensorflow as tf\n",
        "import bert4keras\n",
        "import keras\n",
        "import os\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "print(bert4keras.__version__)\n",
        "import numpy as np\n",
        "from bert4keras.backend import keras, K\n",
        "from bert4keras.models import build_transformer_model\n",
        "from bert4keras.tokenizers import Tokenizer\n",
        "from bert4keras.optimizers import Adam\n",
        "from bert4keras.snippets import sequence_padding, DataGenerator\n",
        "from bert4keras.snippets import open, ViterbiDecoder, to_array\n",
        "from bert4keras.layers import ConditionalRandomField\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model\n",
        "from tqdm import tqdm\n",
        "from  utils import utils\n",
        "from imp import reload\n",
        "reload(utils)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "2.3.1\n",
            "0.9.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils.utils' from '/content/drive/MyDrive/Colab Notebooks/CCF/DBC_code/src/utils/utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUxPSBAu80-G",
        "outputId": "efbae145-97fd-4b9f-d8ed-ea1da0444f56"
      },
      "source": [
        "dict_path = '../model/chinese_L-12_H-768_A-12/vocab.txt'\n",
        "# 建立分词器\n",
        "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
        "str_=\"18618193311\"\n",
        "print(tokenizer.encode(str_)[0][1:-1])#[9833, 8662, 8818, 8921, 8452]\n",
        "tokens = tokenizer.tokenize(str_)#['[CLS]', '186', '##18', '##19', '##33', '##11', '[SEP]']\n",
        "print(\"tokens\",tokens)\n",
        "mapping = tokenizer.rematch(str_, tokens)#[[], [0, 1, 2], [3, 4], [5, 6], [7, 8], [9, 10], []]\n",
        "print(\"mapping\",mapping)\n",
        "token_ids = tokenizer.tokens_to_ids(tokens)#[101, 9833, 8662, 8818, 8921, 8452, 102]\n",
        "print(\"token_ids\",token_ids)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9833, 8662, 8818, 8921, 8452]\n",
            "tokens ['[CLS]', '186', '##18', '##19', '##33', '##11', '[SEP]']\n",
            "mapping [[], [0, 1, 2], [3, 4], [5, 6], [7, 8], [9, 10], []]\n",
            "token_ids [101, 9833, 8662, 8818, 8921, 8452, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXC9w-0nq9pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e990223-9b87-4e33-f0cb-55c919bf9a10"
      },
      "source": [
        "train_data = utils.load_data('../data/train_aug.txt')\n",
        "valid_data = utils.load_data('../data/val_aug.txt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "》\tI-movie\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M37PYSjiq9pt"
      },
      "source": [
        "ret_train_lst = []\n",
        "for data in train_data:\n",
        "    ret = 0\n",
        "    for char,_ in data:\n",
        "        ret += len(char)\n",
        "    ret_train_lst.append(ret)\n",
        "ret_val_lst = []\n",
        "for data in valid_data:\n",
        "    ret = 0\n",
        "    for char,_ in data:\n",
        "        ret += len(char)\n",
        "    ret_val_lst.append(ret)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7eYaUWEq9pt",
        "outputId": "697247b6-4250-4e5d-ef03-689a230e57ae"
      },
      "source": [
        "print(max(ret_train_lst),min(ret_train_lst))\n",
        "print(max(ret_val_lst),min(ret_val_lst))\n",
        "print(len(ret_train_lst))\n",
        "print(len(ret_val_lst))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "344 0\n",
            "300 5\n",
            "48418\n",
            "1352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAUCkMJAq9pt"
      },
      "source": [
        "# 预训练模型的超参数\n",
        "maxlen = 300\n",
        "epochs = 2 #15\n",
        "batch_size = 8\n",
        "bert_layers = 12\n",
        "learing_rate = 1e-5 \n",
        "crf_lr_multiplier = 1000 \n",
        "rnn_lr_multiplier = 1000\n",
        "# bert配置\n",
        "config_path = '../model/chinese_L-12_H-768_A-12/bert_config.json'\n",
        "checkpoint_path = '../model/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
        "dict_path = '../model/chinese_L-12_H-768_A-12/vocab.txt'\n",
        "# 建立分词器\n",
        "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
        "\n",
        "# 类别映射\n",
        "labels = [\n",
        "    'position',\n",
        "    'name',\n",
        "    'organization',\n",
        "    'company',\n",
        "    'address',\n",
        "    'movie',\n",
        "    'game',\n",
        "    'government',\n",
        "    'scene',\n",
        "    'book',\n",
        "    'mobile',\n",
        "    'email',\n",
        "    'QQ',\n",
        "    'vx',\n",
        "]\n",
        "\n",
        "# 0 表示 'O'\n",
        "# 其他数字表示对应的 B 和 I\n",
        "# 其他数字表示对应的 B,I,E,S \n",
        "id2label = dict(enumerate(labels))\n",
        "label2id = {j: i for i, j in id2label.items()}\n",
        "#num_labels = len(labels) * 4 + 1  #BIESO\n",
        "num_labels = len(labels) * 2 + 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuhHYnvJq9pt",
        "outputId": "34b3a429-9593-4a31-97e0-c29f2dce856e"
      },
      "source": [
        "model = build_transformer_model(\n",
        "    config_path,\n",
        "    checkpoint_path,\n",
        ")\n",
        "\n",
        "output_layer = 'Transformer-%s-FeedForward-Norm' % (bert_layers - 1)\n",
        "output = model.get_layer(output_layer).output\n",
        "output = Dense(num_labels)(output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPMotlcZq9pt",
        "outputId": "3858fcd4-a558-482f-ba14-ba7d8deddca0"
      },
      "source": [
        "CRF = ConditionalRandomField(lr_multiplier=crf_lr_multiplier)\n",
        "output = CRF(output)\n",
        "model = Model(model.input, output)\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
            "                                                                 Embedding-Dropout[0][0]          \n",
            "                                                                 Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
            "                                                                 Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
            "                                                                 Transformer-0-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-0-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
            "                                                                 Transformer-1-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
            "                                                                 Transformer-2-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
            "                                                                 Transformer-3-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
            "                                                                 Transformer-4-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
            "                                                                 Transformer-5-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
            "                                                                 Transformer-6-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
            "                                                                 Transformer-7-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
            "                                                                 Transformer-8-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
            "                                                                 Transformer-9-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
            "                                                                 Transformer-10-FeedForward-Dropou\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-10-FeedForward-Norm[0\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
            "                                                                 Transformer-11-FeedForward-Dropou\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_73 (Dense)                (None, None, 29)     22301       Transformer-11-FeedForward-Norm[0\n",
            "__________________________________________________________________________________________________\n",
            "conditional_random_field_1 (Con (None, None, 29)     841         dense_73[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 101,700,198\n",
            "Trainable params: 101,700,198\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyYpa_28q9pt",
        "outputId": "19b8b08b-a1f1-48f9-c0df-8aaaaf23a865"
      },
      "source": [
        "model.compile(\n",
        "    loss=CRF.sparse_loss,\n",
        "    optimizer=Adam(learing_rate),\n",
        "    metrics=[CRF.sparse_accuracy]\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp8XhYMe7iAr"
      },
      "source": [
        "## 对抗训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btnhvdlf7qPy"
      },
      "source": [
        "def search_layers(inputs,name,exclude=None):\r\n",
        "  \"\"\"根据inputs和name来搜索层\r\n",
        "  说明：inputs为某个层或某个层的输出;name为目标层的名字。\r\n",
        "  实现：根据inputs一直往上搜索，直到发现名字为name的层为止\r\n",
        "  如果找不到，那就返回None\r\n",
        "  \"\"\"\r\n",
        "  if exclude is None:\r\n",
        "    exclude=set()\r\n",
        "  if isinstance(inputs,keras.layers.Layer):\r\n",
        "    layer=inputs\r\n",
        "  else:\r\n",
        "    layer=inputs._keras_history[0]\r\n",
        "  \r\n",
        "  if layer.name==name:\r\n",
        "    return layer\r\n",
        "  elif layer in exclude:#之前搜索过不存在返回None\r\n",
        "    return None\r\n",
        "  else:\r\n",
        "    #向上搜索\r\n",
        "    exclude.add(layer)\r\n",
        "    inbound_layers=layer._inbound_nodes[0].inbound_layers\r\n",
        "    if not isinstance(inbound_layers,list):#inbound_layers 不是list\r\n",
        "      inbound_layers=[inbound_layers]#让inbound_layers成list\r\n",
        "    if len(inbound_layers)>0:\r\n",
        "      for layer in inbound_layers:\r\n",
        "        layer=search_layers(layer,name,exclude)#向上搜索\r\n",
        "        if layer is not None:#如果不是空则返回\r\n",
        "          return layer\r\n",
        "\r\n",
        "def adversarial_training(model,embedding_name,epsilon=1):\r\n",
        "  \"\"\"给模型添加对抗训练\r\n",
        "  其中model是需要添加对抗训练的keras模型，embedding_name\r\n",
        "  则是model里边Embedding层的名字。要在模型compile之后使用\r\n",
        "  \"\"\"\r\n",
        "  if model.train_function is None:\r\n",
        "  #compile函数中预定义了一系列训练模型的操作，训练是会调用train_function函数\r\n",
        "    model._make_train_function()#手动make\r\n",
        "  old_train_function =model.train_function#备份旧的训练函数\r\n",
        "\r\n",
        "  #查找Embedding层\r\n",
        "  for output in model.outputs:\r\n",
        "    embedding_layer=search_layers(output,embedding_name)\r\n",
        "    if embedding_layer is not None:\r\n",
        "      break\r\n",
        "  if embedding_layer is None:\r\n",
        "    raise Exception(\"Embedding layer not found\")\r\n",
        "  \r\n",
        "  #求embedding梯度\r\n",
        "  embeddings=embedding_layer.embeddings#Embedding矩阵\r\n",
        "  gradients=K.gradients(model.total_loss,[embeddings])#Embedding梯度\r\n",
        "  gradients=K.zeros_like(embeddings)+gradients[0]#转为dense tensor\r\n",
        "\r\n",
        "  #封装为函数\r\n",
        "  inputs=(model._feed_inputs+model._feed_targets+model._feed_sample_weights)#所有输入层\r\n",
        "  embedding_gradients=K.function(\r\n",
        "      inputs=inputs,\r\n",
        "      outputs=[gradients],\r\n",
        "      name=\"embedding_gradients\"\r\n",
        "  )\r\n",
        "  def train_function(inputs):#重新定义训练函数\r\n",
        "    grades=embedding_gradients(inputs)[0]#Embedding梯度\r\n",
        "    delta=epsilon*grades/(np.sqrt((grades**2).sum())+1e-8)#计算扰动\r\n",
        "    K.set_value(embeddings,K.eval(embeddings)+delta)#注入扰动\r\n",
        "    outputs=old_train_function(inputs)#梯度下降 这里是训练模型更新参数的意思\r\n",
        "    K.set_value(embeddings,K.eval(embeddings)-delta)#删除扰动扰动\r\n",
        "    return outputs\r\n",
        "\r\n",
        "  model.train_function=train_function\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsXy_45UhJK8"
      },
      "source": [
        "adversarial_train=False\r\n",
        "if adversarial_train:\r\n",
        "  adversarial_training(model,\"Embedding-Token\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqt8Tjmfq9pt",
        "outputId": "5825fd4e-2ebd-49d6-b56d-ce7fe5abc1fe"
      },
      "source": [
        "class data_generator(DataGenerator):\n",
        "    \"\"\"\n",
        "    数据生成器\n",
        "    \"\"\"\n",
        "    def __iter__(self, random=False):\n",
        "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
        "        # is_end  是否到 epoch 的末尾， item 对应的 train_data[i]\n",
        "        for is_end, item in self.sample(random):\n",
        "            # vocab.txt 从 0 开始计数，0:[pad] 1-99:[unused*] 100:[UNK] [CLS]:101\n",
        "            # token_ids:101\n",
        "            token_ids, labels = [tokenizer._token_start_id], [0]\n",
        "            for w, l in item:\n",
        "                # 得到除了 [CLS] [SEP] 之外的每一个词的 ids\n",
        "                # e.g '全国青联委员经纪人' -> [1059, 1744, 7471, 5468, 1999, 1447, 5307, 5279, 782]\n",
        "                w_token_ids = tokenizer.encode(w)[0][1:-1]\n",
        "                if len(token_ids) + len(w_token_ids) < maxlen:\n",
        "                    # e.g [101, 1059, 1744, 7471, 5468, 1999, 1447, 5307, 5279, 782]\n",
        "                    # 把 [CLS] 加在前面\n",
        "                    token_ids += w_token_ids\n",
        "                    if l == 'O':\n",
        "                        # 如果是 'O' 则标签是 0\n",
        "                        labels += [0] * len(w_token_ids)\n",
        "                    else:\n",
        "                        # 如果不是 'O' 生成 label2id 对应的标签\n",
        "                        # e.g '全国青联委员经纪人' -> [0, 1, 2, 2, 2, 2, 2, 2, 2, 2] 注意：第一个 [CLS] 默认是 0\n",
        "                        B = label2id[l] * 2 + 1\n",
        "                        I = label2id[l] * 2 + 2\n",
        "                        labels += ([B] + [I] * (len(w_token_ids) - 1))\n",
        "                    # else:\n",
        "                    #   #BIESO\n",
        "                    #   token_len=len(w_token_ids)\n",
        "                    #   if token_len==1:\n",
        "                    #     S=label2id[l]*4+4\n",
        "                    #     label+=([S])\n",
        "                    #   elif token_len==2:\n",
        "                    #     B=label2id[l]*4+1\n",
        "                    #     E=label2id[l]*4+3\n",
        "                    #     label+=([B]+[E])\n",
        "                    #   else:\n",
        "                    #     B=label2id[l]*4+1\n",
        "                    #     I=label2id[l]*4+2\n",
        "                    #     E=label2id[l]*4+3\n",
        "                    #     label+=([B]+[I]*(token_len-2)+[E])\n",
        "                else:\n",
        "                    # 超过 maxlen 长度的部分被舍弃掉\n",
        "                    break\n",
        "            # 加上尾巴 [SEP]:102\n",
        "            token_ids += [tokenizer._token_end_id]\n",
        "            # 尾巴的 label 也是 0\n",
        "            labels += [0]\n",
        "            # 生成 segment_ids ，NER 只用了一个句子，所以这里都是 0\n",
        "            segment_ids = [0] * len(token_ids)\n",
        "            # 把样本组装成 batch\n",
        "            batch_token_ids.append(token_ids)\n",
        "            batch_segment_ids.append(segment_ids)\n",
        "            batch_labels.append(labels)\n",
        "            # 如果凑齐了 batchsize 个，或者到 epoch 的最后一个，那么就返回。\n",
        "            if len(batch_token_ids) == self.batch_size or is_end:\n",
        "                # 进行 padding 操作\n",
        "                # [bs,seq] 默认按照 bs 中最大的长度进行填充，保证每个 bs 的长度是一致，用 0 填充\n",
        "                batch_token_ids = sequence_padding(batch_token_ids)\n",
        "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
        "                batch_labels = sequence_padding(batch_labels)\n",
        "                yield [batch_token_ids, batch_segment_ids], batch_labels\n",
        "                batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
        "\n",
        "\n",
        "\n",
        "class NamedEntityRecognizer(ViterbiDecoder):\n",
        "    \"\"\"\n",
        "    命名实体识别器\n",
        "    \"\"\"\n",
        "    def recognize(self, text):\n",
        "        tokens = tokenizer.tokenize(text)#['[CLS]', '186', '##18', '##19', '##33', '##11', '[SEP]']\n",
        "        mapping = tokenizer.rematch(text, tokens)#[[], [0, 1, 2], [3, 4], [5, 6], [7, 8], [9, 10], []]\n",
        "        token_ids = tokenizer.tokens_to_ids(tokens)#[101, 9833, 8662, 8818, 8921, 8452, 102]\n",
        "        segment_ids = [0] * len(token_ids)\n",
        "        token_ids, segment_ids = to_array([token_ids], [segment_ids])\n",
        "        nodes = model.predict([token_ids, segment_ids])[0]\n",
        "        labels = self.decode(nodes)\n",
        "        entities, starting = [], False\n",
        "        for i, label in enumerate(labels):\n",
        "            if label > 0:\n",
        "                if label % 2 == 1:\n",
        "                    starting = True\n",
        "                    entities.append([[i], id2label[(label - 1) // 2]])\n",
        "                elif starting:\n",
        "                    entities[-1][0].append(i)\n",
        "                else:\n",
        "                    starting = False\n",
        "            else:\n",
        "                starting = False\n",
        "        # for i,label in enumerate(labels):\n",
        "        # BIES\n",
        "        #   if label >0:\n",
        "        #     if label%4==1:# B-实体标签 标签\n",
        "        #       starting=True\n",
        "        #       entities.append([[i],id2label[(label-1)//4]])# 0是CLS和SEQ的标签\n",
        "        #     elif label%4==0:#S-实体标签 标签 \n",
        "        #       starting=False\n",
        "        #       entities.append([[i],id2label[(label-4)//4]])\n",
        "        #     elif starting:\n",
        "        #       entities[-1][0].append(i)\n",
        "        #     else:\n",
        "        #       starting=False\n",
        "        #   else:\n",
        "        #     starting=False\n",
        "\n",
        "        return [(text[mapping[w[0]][0]:mapping[w[-1]][-1] + 1], l)\n",
        "                for w, l in entities]\n",
        "\n",
        "\n",
        "NER = NamedEntityRecognizer(trans=K.eval(CRF.trans), starts=[0], ends=[0])\n",
        "\n",
        "\n",
        "def evaluate(data):\n",
        "    \"\"\"评测函数\n",
        "    \"\"\"\n",
        "    X, Y, Z = 1e-10, 1e-10, 1e-10\n",
        "    for d in tqdm(data):\n",
        "        # d: [[text,label],...]\n",
        "        text = ''.join([i[0] for i in d])\n",
        "        # 预测标签 {('卡卡','name'),('深度之眼','organization'),...}\n",
        "        R = set(NER.recognize(text)) \n",
        "        # 真实标签 {('卡卡','name'),('深度之眼','organization'),...}\n",
        "        T = set([tuple(i) for i in d if i[1] != 'O'])\n",
        "        # 只有标签类别和识别名字完全对应上才会有值\n",
        "        X += len(R & T) \n",
        "        # 所有预测为 “正” 样本的标签\n",
        "        Y += len(R) \n",
        "        # 所有真实为 “正” 样本的标签\n",
        "        Z += len(T)\n",
        "    # 查准率和查全率\n",
        "    precision, recall =  X / Y, X / Z\n",
        "    f1 = 2*precision*recall/(precision+recall)\n",
        "    return f1, precision, recall\n",
        "\n",
        "\n",
        "class Evaluator(keras.callbacks.Callback):\n",
        "    def __init__(self,valid_data):\n",
        "        self.best_val_f1 = 0\n",
        "        self.valid_data = valid_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        trans = K.eval(CRF.trans)\n",
        "        NER.trans = trans\n",
        "#         print(NER.trans)\n",
        "        # 计算验证集的评估指标\n",
        "        f1, precision, recall = evaluate(self.valid_data)\n",
        "        # 保存最优\n",
        "        if f1 >= self.best_val_f1:\n",
        "            self.best_val_f1 = f1\n",
        "            model.save_weights('../model/best_model_epoch_10.weights')\n",
        "        print(\n",
        "            'valid:  f1: %.5f, precision: %.5f, recall: %.5f, best f1: %.5f\\n' %\n",
        "            (f1, precision, recall, self.best_val_f1)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "evaluator = Evaluator(valid_data)\n",
        "train_generator = data_generator(train_data, batch_size)\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator.forfit(),\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=epochs,\n",
        "    callbacks=[evaluator]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/2\n",
            "2783/6053 [============>.................] - ETA: 19:46 - loss: 7.0730 - sparse_accuracy: 0.8540"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDeZxLvnA8i_"
      },
      "source": [
        "# 数据处理参数\n",
        "symbol = ['？','⋯','…','﹗']\n",
        "max_sent_length = 250\n",
        "max_input_length = 300     \n",
        "# 建立分词器\n",
        "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
        "# 类别映射\n",
        "labels = [\n",
        "    'position',\n",
        "    'name',\n",
        "    'organization',\n",
        "    'company',\n",
        "    'address',\n",
        "    'movie',\n",
        "    'game',\n",
        "    'government',\n",
        "    'scene',\n",
        "    'book',\n",
        "    'mobile',\n",
        "    'email',\n",
        "    'QQ',\n",
        "    'vx',\n",
        "]\n",
        "# 0 表示 'O'\n",
        "# 其他数字表示对应的 B 和 I\n",
        "id2label = dict(enumerate(labels))\n",
        "label2id = {j: i for i, j in id2label.items()}\n",
        "num_labels = len(labels) * 2 + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzPb1N7oq9pt"
      },
      "source": [
        "model_path = '../model/best_model_epoch_10.weights'\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkgleCfkspBY"
      },
      "source": [
        "class NamedEntityRecognizer(ViterbiDecoder):\n",
        "    \"\"\"\n",
        "    命名实体识别器\n",
        "    \"\"\"\n",
        "    def recognize(self, text):\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        mapping = tokenizer.rematch(text, tokens)\n",
        "        token_ids = tokenizer.tokens_to_ids(tokens)\n",
        "        segment_ids = [0] * len(token_ids)\n",
        "        nodes = model.predict([[token_ids], [segment_ids]])[0]\n",
        "        labels = self.decode(nodes)\n",
        "        entities, starting = [], False\n",
        "        \n",
        "        for i, label in enumerate(labels):\n",
        "            if label > 0:\n",
        "                if label % 2 == 1:\n",
        "                    starting = True\n",
        "                    entities.append([[i], id2label[(label - 1) // 2]])\n",
        "                elif starting:\n",
        "                    entities[-1][0].append(i)\n",
        "                else:\n",
        "                    starting = False\n",
        "            else:\n",
        "                starting = False\n",
        "\n",
        "        return [(text[mapping[w[0]][0]:mapping[w[-1]][-1] + 1], l)\n",
        "                for w, l in entities]\n",
        "        #[(中国，ORG)，（12345678912，mobile）,.....]\n",
        "    \n",
        "    \n",
        "NER = NamedEntityRecognizer(trans=K.eval(CRF.trans), starts=[0], ends=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sC6CLZ-sr-u"
      },
      "source": [
        "def test_predict(data, NER_):\n",
        "    test_ner =[]\n",
        "    for text in tqdm(data):\n",
        "        cut_text_list, cut_index_list = utils.agg_sent([text],symbol, max_sent_length, max_input_length)\n",
        "        posit = 0\n",
        "        item_ner = []\n",
        "        index =1\n",
        "        for str_ in cut_text_list:#[str_1,str_2] str_：一段字符串\n",
        "            ner_res  = NER_.recognize(str_)\n",
        "            for tn in ner_res:\n",
        "                ans = {}\n",
        "                ans[\"label_type\"] = tn[1]#标签\n",
        "                ans['index'] = str(index)#一个txt识别预测出来的多少个实体\n",
        "                ans[\"start_pos\"] = text.find(tn[0],posit)\n",
        "                ans[\"end_pos\"] = ans[\"start_pos\"] + len(tn[0])-1\n",
        "                posit = ans[\"end_pos\"]\n",
        "                ans[\"res\"] = tn[0]#对应的实体字符串\n",
        "                item_ner.append(ans)#[{},{},{},{}]\n",
        "                index +=1\n",
        "        test_ner.append(item_ner)#[[{},{},{},{},{},{},{},{}],[{},{},{},{},{},{},{},{}]]\n",
        "                       #text1     \n",
        "    return test_ner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEjrjukhst_l"
      },
      "source": [
        "from glob import glob\n",
        "test_files = glob(\"../data/test_data/*.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKeSl827sxMc"
      },
      "source": [
        "df_ret = {'ID':[],'Category':[],'Pos_b':[],'Pos_e':[],'Privacy':[]}\n",
        "for file in test_files:\n",
        "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "        line = f.read()\n",
        "        line = [line]\n",
        "        ret = test_predict(line, NER)\n",
        "    idx = os.path.basename(file).split('.')[0]\n",
        "    for line in ret[0]:#这里取【0】的原因是open开的是一段完整的文字，所以识别后返回的也是一段的实体识别标签\n",
        "        df_ret['ID'].append(idx)\n",
        "        df_ret['Category'].append(line['label_type'].strip('\\n'))\n",
        "        df_ret['Pos_b'].append(line['start_pos'])\n",
        "        df_ret['Pos_e'].append(line['end_pos'])\n",
        "        df_ret['Privacy'].append(line['res'].replace('\\n',''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS7xOdAVBOAN"
      },
      "source": [
        "# Submit 提交\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv1T776Us1OO"
      },
      "source": [
        "import pandas as pd\n",
        "version = '20201101'\n",
        "df_ret_ = pd.DataFrame(df_ret)\n",
        "df_ret_ = df_ret_.sort_values('ID')\n",
        "df_ret_.to_csv('../submit/predict{}.csv'.format(version),index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7SzK5nqs3Fh"
      },
      "source": [
        "file_name = '../submit/predict{}.csv'.format(version)\n",
        "utils.checkout(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZC2vtiKyigG"
      },
      "source": [
        "## 后处理的部分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z5TSLgW-FG9"
      },
      "source": [
        "import pandas as pd\r\n",
        "import os \r\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/CCF/DBC_code/src\")\r\n",
        "pred=pd.read_csv('../submit/predict20201101.csv')\r\n",
        "pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkXqJJev-V_m"
      },
      "source": [
        "import re\r\n",
        "reg = re.compile(r'(《.*》)')\r\n",
        "#re.findall返回的是list，没有匹配成功就是\r\n",
        "uncomplete_yinhao_book = pred[pred.Category == 'book'][(pred[pred.Category == 'book'].Privacy.apply(c:re.findall(reg,x)).apply(lambda x:len(x))!=1)]\r\n",
        "temp =    pred[pred.Category == 'book'][(pred[pred.Category == 'book'].Privacy.apply(lambda x:re.findall(reg,x)).apply(lambda x:len(x))!=1)]\r\n",
        "half_yinghao_book = temp[temp.Privacy.apply(lambda x :('《' in x or '》' in x))]\r\n",
        "uncomplete_yinhao_book.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-OTutsr_fxA"
      },
      "source": [
        "half_yinghao_book.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGld5tV3yYSQ"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "def repair_book(bad_data_book,max_len = 20):\r\n",
        "    ret = {'ID':[],'Category':[],'Pos_b':[],'Pos_e':[],'Privacy':[]}\r\n",
        "    for idx,cat,pos_b,pos_e,privacy in tqdm(bad_data_book.values):\r\n",
        "        if '《' in privacy:\r\n",
        "            with open('../data/test_data/{}.txt'.format(idx),'r') as f:\r\n",
        "                content = f.readline()\r\n",
        "            for i in range(1, min(len(content)-pos_e-1,max_len)):\r\n",
        "                index  = pos_e + i\r\n",
        "                if content[index] in (',.。!！《'):\r\n",
        "                    break\r\n",
        "                if content[index] == '》':\r\n",
        "                    pos_e = index\r\n",
        "                    break\r\n",
        "            ret['ID'].append(idx)\r\n",
        "            ret['Category'].append(cat)\r\n",
        "            ret['Pos_b'].append(pos_b)\r\n",
        "            ret['Pos_e'].append(pos_e)\r\n",
        "            ret['Privacy'].append(content[pos_b:pos_e+1])\r\n",
        "        if '》' in privacy:\r\n",
        "            with open('../data/test_data/{}.txt'.format(idx),'r') as f:\r\n",
        "                content = f.readline()\r\n",
        "            for i in range(1,min(pos_b,max_len)):\r\n",
        "                index  = pos_b -1 - i\r\n",
        "                if content[index] in (',.。!！》'):\r\n",
        "                    break\r\n",
        "                if content[index] == '《':\r\n",
        "                    pos_b = index\r\n",
        "                    break\r\n",
        "            ret['ID'].append(idx)\r\n",
        "            ret['Category'].append(cat)\r\n",
        "            ret['Pos_b'].append(pos_b)\r\n",
        "            ret['Pos_e'].append(pos_e)\r\n",
        "            ret['Privacy'].append(content[pos_b:pos_e+1])\r\n",
        "    return ret\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBCEuhg-GYbR"
      },
      "source": [
        "repair_ret=repair_book(half_yinghao_book,max_len = 20)\r\n",
        "repair_ret=pd.DataFrame(repair_ret)\r\n",
        "repair_ret.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk2ej4OhHFj6"
      },
      "source": [
        "pred.loc[half_yinghao_book.index]=repair_ret.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p0ZQwT-HbZJ"
      },
      "source": [
        "pred.loc[half_yinghao_book.index].head()\r\n",
        "#GameInformer》 这几个数据都是数据本身有问题无法搜索到补全《的信息"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mc64g8KHqY_"
      },
      "source": [
        "pred=pred.drop_duplicates()\r\n",
        "print(pred[pred.ID==1127])\r\n",
        "pred.to_csv('../submit/predict_postprocess.csv',index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-YHudxmysOj"
      },
      "source": [
        "## 差分学习率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyfNuGY9yrUm"
      },
      "source": [
        "import keras.backend as K\r\n",
        "class SetLearningRate:\r\n",
        "    \"\"\"层的一个包装，用来设置当前层的学习率\r\n",
        "    引用自 keras4bert 作者代码\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, layer, lamb, is_ada=False):\r\n",
        "        self.layer = layer\r\n",
        "        self.lamb = lamb # 学习率比例\r\n",
        "        self.is_ada = is_ada # 是否自适应学习率优化器\r\n",
        "\r\n",
        "    def __call__(self, inputs):\r\n",
        "        with K.name_scope(self.layer.name):\r\n",
        "            if not self.layer.built:\r\n",
        "                input_shape = K.int_shape(inputs)#inputs的形状\r\n",
        "                self.layer.build(input_shape)#重建模型层\r\n",
        "                self.layer.built = True#训练True\r\n",
        "                if self.layer._initial_weights is not None:\r\n",
        "                    self.layer.set_weights(self.layer._initial_weights)#初始化层参数权重\r\n",
        "        for key in ['kernel', 'bias', 'embeddings', 'depthwise_kernel', 'pointwise_kernel', 'recurrent_kernel', 'gamma', 'beta']:\r\n",
        "#                              模型层的一些可学习参数\r\n",
        "            if hasattr(self.layer, key):#查看layer是否有key值的属性\r\n",
        "                weight = getattr(self.layer, key)#获取值\r\n",
        "                if self.is_ada:\r\n",
        "                    lamb = self.lamb # 自适应学习率优化器直接保持lamb比例\r\n",
        "                else:\r\n",
        "                    lamb = self.lamb**0.5 # SGD（包括动量加速），lamb要开平方\r\n",
        "                K.set_value(weight, K.eval(weight) / lamb) # 更改初始化\r\n",
        "                setattr(self.layer, key, weight * lamb) # 按比例替换\r\n",
        "        return self.layer(inputs)\r\n",
        "\r\n",
        "# 使用方法\r\n",
        "# 构建层，然后用 SetLearningRate 包在层的外面，rnn_lr_multiplier 为要放大的学习率倍数，如果是自适应的梯度下降法，设置 is_ada = True\r\n",
        "brnn = Bidirectional(GRU(128, return_sequences=True),merge_mode='sum')\r\n",
        "brnn_mul = SetLearningRate(brnn,lamb = rnn_lr_multiplier,is_ada = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}